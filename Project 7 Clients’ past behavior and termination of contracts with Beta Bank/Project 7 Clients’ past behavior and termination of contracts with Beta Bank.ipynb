{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Description:\n",
    "\n",
    "Beta Bank customers are leaving: little by little, chipping away every month. The bankers figured out it’s cheaper to save the existing customers rather than to attract new ones.\n",
    "\n",
    "***We need to predict whether a customer will leave the bank soon.*** We have the data on clients’ past behavior and termination of contracts with the bank.\n",
    "\n",
    "We will find one machine learning model with the maximum possible F1  score to make the predictions.\n",
    "\n",
    "**Features:**\n",
    "\n",
    "*RowNumber*  — data string index \n",
    "\n",
    "*CustomerId*  — unique customer identifier \n",
    "\n",
    "*Surname*  — surname\n",
    "\n",
    "*CreditScore*  — credit score\n",
    "\n",
    "*Geography*  — country of residence \n",
    "\n",
    "*Gender*  — gender\n",
    "\n",
    "*Age*  — age\n",
    "\n",
    "*Tenure*  — period of maturation for a customer’s fixed deposit (years) \n",
    "\n",
    "*Balance*  — account balance\n",
    "\n",
    "*NumOfProducts*  — number of banking products used by the customer \n",
    "\n",
    "*HasCrCard*  — customer has a credit card\n",
    "\n",
    "*IsActiveMember*  — customer’s activeness EstimatedSalary  — estimated salary\n",
    "\n",
    "**Target:**\n",
    "\n",
    "*Exited*  — сustomer has left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Overview of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary Packages \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from joblib import dump\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    data = pd.read_csv('Churn.csv')\n",
    "except:\n",
    "    data = pd.read_csv('/datasets/Churn.csv')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates\n",
    "data.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tenure\n",
      "mean: 4.997690023099769\n",
      "median: 5.0\n",
      "std: 2.894723234821264\n",
      "max: 10.0\n",
      "min: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Look into the column with missing data\n",
    "print('Tenure')\n",
    "print('mean:', data['Tenure'].mean())\n",
    "print('median:', data['Tenure'].median())\n",
    "print('std:', data['Tenure'].std())\n",
    "print('max:', data['Tenure'].max())\n",
    "print('min:', data['Tenure'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           10000 non-null  float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Mean and median of the values are close to each other\n",
    "# We can choose either of mean or median to fill in the missing values\n",
    "data['Tenure'].fillna(value = data['Tenure'].median(), inplace = True)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description:**\n",
    "\n",
    "Here we replace the missing values of Tenure with median value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Features & Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10000 entries, 0 to 9999\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   CreditScore      10000 non-null  int64  \n",
      " 1   Geography        10000 non-null  object \n",
      " 2   Gender           10000 non-null  object \n",
      " 3   Age              10000 non-null  int64  \n",
      " 4   Tenure           10000 non-null  float64\n",
      " 5   Balance          10000 non-null  float64\n",
      " 6   NumOfProducts    10000 non-null  int64  \n",
      " 7   HasCrCard        10000 non-null  int64  \n",
      " 8   IsActiveMember   10000 non-null  int64  \n",
      " 9   EstimatedSalary  10000 non-null  float64\n",
      " 10  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(6), object(2)\n",
      "memory usage: 937.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# RowNumber, CustomerId and Surname are not relevant to the prediction, we can exclude them\n",
    "data.drop(['RowNumber', 'CustomerId' ,'Surname'], axis = 1, inplace = True)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   CreditScore        10000 non-null  int64  \n",
      " 1   Age                10000 non-null  int64  \n",
      " 2   Tenure             10000 non-null  float64\n",
      " 3   Balance            10000 non-null  float64\n",
      " 4   NumOfProducts      10000 non-null  int64  \n",
      " 5   HasCrCard          10000 non-null  int64  \n",
      " 6   IsActiveMember     10000 non-null  int64  \n",
      " 7   EstimatedSalary    10000 non-null  float64\n",
      " 8   Exited             10000 non-null  int64  \n",
      " 9   Geography_France   10000 non-null  uint8  \n",
      " 10  Geography_Germany  10000 non-null  uint8  \n",
      " 11  Geography_Spain    10000 non-null  uint8  \n",
      " 12  Gender_Female      10000 non-null  uint8  \n",
      " 13  Gender_Male        10000 non-null  uint8  \n",
      "dtypes: float64(3), int64(6), uint8(5)\n",
      "memory usage: 830.1 KB\n"
     ]
    }
   ],
   "source": [
    "# Transform categorical features into numerical features (Geography & Gender)\n",
    "data = pd.get_dummies(data)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features and Target\n",
    "features = data.drop(['Exited'], axis = 1)\n",
    "target = data['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Exited : 2037\n",
      "Others : 7963\n"
     ]
    }
   ],
   "source": [
    "# Look into the imbalance classes\n",
    "print('Number of Exited :', target.sum())    \n",
    "print('Others :', target.count() - target.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description**\n",
    "\n",
    "It seems that in the data there are much more people who didn't exit than those who did. So the original data is not balanced.\n",
    "\n",
    "The number of **0s** is approximatly *4 times* that of **1s**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training with imbalaced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the features and target into train, valid and test sets\n",
    "features_train_valid, features_test, target_train_valid, target_test = train_test_split(features, target,\n",
    "                                                              test_size=0.25, random_state=12345)\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(features_train_valid, target_train_valid,\n",
    "                                                              test_size=0.25, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 6\n",
      "F1 score based on validation set: 0.5652173913043478\n",
      "AUC-ROC Score : 0.835889808132371\n",
      "\n",
      "max_depth = 7\n",
      "F1 score based on validation set: 0.5657237936772047\n",
      "AUC-ROC Score : 0.8403018834712199\n",
      "\n",
      "max_depth = 8\n",
      "F1 score based on validation set: 0.5766871165644172\n",
      "AUC-ROC Score : 0.8269785249075867\n",
      "\n",
      "max_depth = 9\n",
      "F1 score based on validation set: 0.5807453416149069\n",
      "AUC-ROC Score : 0.8085944375990143\n",
      "\n",
      "max_depth = 10\n",
      "F1 score based on validation set: 0.5752212389380531\n",
      "AUC-ROC Score : 0.7818482661503257\n",
      "\n",
      "max_depth = 11\n",
      "F1 score based on validation set: 0.5689900426742532\n",
      "AUC-ROC Score : 0.7790802675585284\n",
      "\n",
      "max_depth = 12\n",
      "F1 score based on validation set: 0.5571030640668524\n",
      "AUC-ROC Score : 0.7593434254532652\n",
      "\n",
      "max_depth = 13\n",
      "F1 score based on validation set: 0.5471447543160691\n",
      "AUC-ROC Score : 0.7387026931878189\n",
      "\n",
      "max_depth = 14\n",
      "F1 score based on validation set: 0.5383615084525358\n",
      "AUC-ROC Score : 0.7231191691603591\n",
      "\n",
      "max_depth = 15\n",
      "F1 score based on validation set: 0.5340314136125656\n",
      "AUC-ROC Score : 0.7197086780496391\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DecisionTreeClassifier\n",
    "for i in range(6, 16):\n",
    "    # Train the models of different max_depth values with training set\n",
    "    model = DecisionTreeClassifier(random_state = 12345, max_depth = i)\n",
    "    model.fit(features_train, target_train)\n",
    "    # check the models of different max_depth values with the validation set\n",
    "    predict_valid = model.predict(features_valid)\n",
    "    f1 = f1_score(target_valid, predict_valid)\n",
    "    probabilities_valid = model.predict_proba(features_valid)\n",
    "    probabilities_one_valid = probabilities_valid[:, 1]\n",
    "    auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "    print('max_depth =', i)\n",
    "    print('F1 score based on validation set:', f1)\n",
    "    print('AUC-ROC Score :', auc_roc)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier\n",
      "F1 score based on test set: 0.5504587155963303\n",
      "AUC-ROC Score : 0.8034605597964376\n"
     ]
    }
   ],
   "source": [
    "# Choose max_depth = 9 as the final model to be tested\n",
    "model_DecisionTree =  DecisionTreeClassifier(random_state = 12345, max_depth = 9)\n",
    "model_DecisionTree.fit(features_train_valid, target_train_valid)\n",
    "# Test its recall and precision metrix with testing set\n",
    "predict_test = model_DecisionTree.predict(features_test)\n",
    "print('DecisionTreeClassifier')\n",
    "f1 = f1_score(target_test, predict_test)\n",
    "probabilities_test = model_DecisionTree.predict_proba(features_test)\n",
    "probabilities_one_test = probabilities_test[:, 1]\n",
    "auc_roc = roc_auc_score(target_test, probabilities_one_test)\n",
    "print('F1 score based on test set:', f1)\n",
    "print('AUC-ROC Score :', auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 10\n",
      "F1 score based on validation set: 0.5439739413680781\n",
      "AUC-ROC Score : 0.818523147333216\n",
      "\n",
      "n_estimators = 20\n",
      "F1 score based on validation set: 0.5648604269293924\n",
      "AUC-ROC Score : 0.8390529836296426\n",
      "\n",
      "n_estimators = 30\n",
      "F1 score based on validation set: 0.5742251223491027\n",
      "AUC-ROC Score : 0.849307340256997\n",
      "\n",
      "n_estimators = 40\n",
      "F1 score based on validation set: 0.5770491803278688\n",
      "AUC-ROC Score : 0.8516352754796691\n",
      "\n",
      "n_estimators = 50\n",
      "F1 score based on validation set: 0.5718954248366013\n",
      "AUC-ROC Score : 0.8531279704277417\n",
      "\n",
      "n_estimators = 60\n",
      "F1 score based on validation set: 0.567699836867863\n",
      "AUC-ROC Score : 0.8560579123393769\n",
      "\n",
      "n_estimators = 70\n",
      "F1 score based on validation set: 0.565359477124183\n",
      "AUC-ROC Score : 0.8574942791762015\n",
      "\n",
      "n_estimators = 80\n",
      "F1 score based on validation set: 0.5644371941272431\n",
      "AUC-ROC Score : 0.8580153142052456\n",
      "\n",
      "n_estimators = 90\n",
      "F1 score based on validation set: 0.568144499178982\n",
      "AUC-ROC Score : 0.8594490406618553\n",
      "\n",
      "n_estimators = 100\n",
      "F1 score based on validation set: 0.5737704918032787\n",
      "AUC-ROC Score : 0.8606495335328287\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RandomForestClassifier\n",
    "for i in range(1, 11):\n",
    "    # Train the models of different n_estimators values with training set\n",
    "    model = RandomForestClassifier(random_state = 12345, n_estimators = i * 10)\n",
    "    model.fit(features_train, target_train)\n",
    "    # check the models of different n_estimators values with the validation set\n",
    "    predict_valid = model.predict(features_valid)\n",
    "    f1 = f1_score(target_valid, predict_valid)\n",
    "    probabilities_valid = model.predict_proba(features_valid)\n",
    "    probabilities_one_valid = probabilities_valid[:, 1]\n",
    "    auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "    print('n_estimators =', i * 10)\n",
    "    print('F1 score based on validation set:', f1)\n",
    "    print('AUC-ROC Score :', auc_roc)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 90\n",
      "max_depth = 6\n",
      "F1 score based on validation set: 0.48030018761726073\n",
      "AUC-ROC Score : 0.8660042246083437\n",
      "\n",
      "n_estimators = 90\n",
      "max_depth = 7\n",
      "F1 score based on validation set: 0.5223613595706619\n",
      "AUC-ROC Score : 0.8696409082907939\n",
      "\n",
      "n_estimators = 90\n",
      "max_depth = 8\n",
      "F1 score based on validation set: 0.5422535211267605\n",
      "AUC-ROC Score : 0.869616264742123\n",
      "\n",
      "n_estimators = 90\n",
      "max_depth = 9\n",
      "F1 score based on validation set: 0.5479452054794521\n",
      "AUC-ROC Score : 0.870007041013906\n",
      "\n",
      "n_estimators = 90\n",
      "max_depth = 10\n",
      "F1 score based on validation set: 0.5519591141396933\n",
      "AUC-ROC Score : 0.8681975004400633\n",
      "\n",
      "n_estimators = 90\n",
      "max_depth = 11\n",
      "F1 score based on validation set: 0.5680272108843538\n",
      "AUC-ROC Score : 0.8654814293258228\n",
      "\n",
      "n_estimators = 90\n",
      "max_depth = 12\n",
      "F1 score based on validation set: 0.5647058823529412\n",
      "AUC-ROC Score : 0.8650660095053687\n",
      "\n",
      "n_estimators = 90\n",
      "max_depth = 13\n",
      "F1 score based on validation set: 0.5681063122923588\n",
      "AUC-ROC Score : 0.8646673120929416\n",
      "\n",
      "n_estimators = 90\n",
      "max_depth = 14\n",
      "F1 score based on validation set: 0.5785123966942148\n",
      "AUC-ROC Score : 0.8602922020770992\n",
      "\n",
      "n_estimators = 90\n",
      "max_depth = 15\n",
      "F1 score based on validation set: 0.5657237936772047\n",
      "AUC-ROC Score : 0.8598891040309804\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Specify the n_estimators = 90\n",
    "for i in range(6, 16):\n",
    "    # Train the models of different max_depth values with training set\n",
    "    model = RandomForestClassifier(random_state = 12345, n_estimators = 90, max_depth = i)\n",
    "    model.fit(features_train, target_train)\n",
    "    # check the models of different max_depth values with the validation set\n",
    "    predict_valid = model.predict(features_valid)\n",
    "    f1 = f1_score(target_valid, predict_valid)\n",
    "    probabilities_valid = model.predict_proba(features_valid)\n",
    "    probabilities_one_valid = probabilities_valid[:, 1]\n",
    "    auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "    print('n_estimators = 90')\n",
    "    print('max_depth =', i)\n",
    "    print('F1 score based on validation set:', f1)\n",
    "    print('AUC-ROC Score :', auc_roc)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier\n",
      "F1 score based on test set: 0.5635491606714629\n",
      "AUC-ROC Score : 0.8524848398373402\n"
     ]
    }
   ],
   "source": [
    "# Choose n_estimators = 90, max_depth = 14 as the final model to be tested\n",
    "model_RandomForest =  RandomForestClassifier(random_state = 12345, n_estimators = 90, max_depth = 14)\n",
    "model_RandomForest.fit(features_train_valid, target_train_valid)\n",
    "# Test its recall and precision metrix with testing set\n",
    "predict_test = model_RandomForest.predict(features_test)\n",
    "print('RandomForestClassifier')\n",
    "f1 = f1_score(target_test, predict_test)\n",
    "probabilities_test = model_RandomForest.predict_proba(features_test)\n",
    "probabilities_one_test = probabilities_test[:, 1]\n",
    "auc_roc = roc_auc_score(target_test, probabilities_one_test)\n",
    "print('F1 score based on test set:', f1)\n",
    "print('AUC-ROC Score :', auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solver = newton-cg\n",
      "F1 score based on validation set: 0.3107569721115538\n",
      "AUC-ROC Score : 0.7790107375462068\n",
      "\n",
      "solver = lbfgs\n",
      "F1 score based on validation set: 0.10232558139534884\n",
      "AUC-ROC Score : 0.6884932230241154\n",
      "\n",
      "solver = liblinear\n",
      "F1 score based on validation set: 0.09389671361502347\n",
      "AUC-ROC Score : 0.6982221439887344\n",
      "\n",
      "solver = sag\n",
      "F1 score based on validation set: 0.0\n",
      "AUC-ROC Score : 0.4906829783488822\n",
      "\n",
      "solver = saga\n",
      "F1 score based on validation set: 0.0\n",
      "AUC-ROC Score : 0.4737282168632283\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LogisticRegression\n",
    "for method in ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']:\n",
    "    # Train the models of different solver values with training set\n",
    "    model = LogisticRegression(random_state = 12345, solver = method)\n",
    "    model.fit(features_train, target_train)\n",
    "    # check the models of different solver values with the validation set\n",
    "    predict_valid = model.predict(features_valid)\n",
    "    f1 = f1_score(target_valid, predict_valid)\n",
    "    probabilities_valid = model.predict_proba(features_valid)\n",
    "    probabilities_one_valid = probabilities_valid[:, 1]\n",
    "    auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "    print('solver =', method)\n",
    "    print('F1 score based on validation set:', f1)\n",
    "    print('AUC-ROC Score :', auc_roc)\n",
    "    print()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "F1 score based on test set: 0.2921985815602837\n",
      "AUC-ROC Score : 0.7516938955078358\n"
     ]
    }
   ],
   "source": [
    "# Choose solver = newton-cg as the final model to be tested\n",
    "model_LogisticRegression =  LogisticRegression(random_state = 12345, solver = 'newton-cg')\n",
    "model_LogisticRegression.fit(features_train_valid, target_train_valid)\n",
    "# Test its recall and precision metrix with testing set\n",
    "predict_test = model_LogisticRegression.predict(features_test)\n",
    "print('LogisticRegression')\n",
    "f1 = f1_score(target_test, predict_test)\n",
    "probabilities_test = model_LogisticRegression.predict_proba(features_test)\n",
    "probabilities_one_test = probabilities_test[:, 1]\n",
    "auc_roc = roc_auc_score(target_test, probabilities_one_test)\n",
    "print('F1 score based on test set:', f1)\n",
    "print('AUC-ROC Score :', auc_roc)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description**\n",
    "\n",
    "When trained with **imbalanced** data, among all the models above, the ***RandomForestClassifier*** model with *random_state = 12345*, *n_estimators = 90* and *max_depth = 14* has the highest **F1 Score (0.5680473372781064)** based on test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training with balaced data (Upsampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsampling those who exited\n",
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "\n",
    "    features_upsampled, target_upsampled = shuffle(\n",
    "        features_upsampled, target_upsampled, random_state=12345\n",
    "    )\n",
    "\n",
    "    return features_upsampled, target_upsampled\n",
    "\n",
    "features_train_1, target_train_1 = upsample(features_train, target_train, repeat = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Exited : 4488\n",
      "Others : 4503\n"
     ]
    }
   ],
   "source": [
    "# Look into the imbalance classes\n",
    "print('Number of Exited :', target_train_1.sum())    \n",
    "print('Others :', target_train_1.count() - target_train_1.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description**\n",
    "\n",
    "Now the 2 classes are more balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 6\n",
      "F1 score based on validation set: 0.5759059745347698\n",
      "AUC-ROC Score : 0.8453230065129379\n",
      "\n",
      "max_depth = 7\n",
      "F1 score based on validation set: 0.5687203791469194\n",
      "AUC-ROC Score : 0.8417901777856012\n",
      "\n",
      "max_depth = 8\n",
      "F1 score based on validation set: 0.5695931477516061\n",
      "AUC-ROC Score : 0.8172689667312092\n",
      "\n",
      "max_depth = 9\n",
      "F1 score based on validation set: 0.5496031746031746\n",
      "AUC-ROC Score : 0.7987229361027988\n",
      "\n",
      "max_depth = 10\n",
      "F1 score based on validation set: 0.5675392670157068\n",
      "AUC-ROC Score : 0.7896250660095054\n",
      "\n",
      "max_depth = 11\n",
      "F1 score based on validation set: 0.5267576075550893\n",
      "AUC-ROC Score : 0.7563316317549726\n",
      "\n",
      "max_depth = 12\n",
      "F1 score based on validation set: 0.5138592750533049\n",
      "AUC-ROC Score : 0.7437827847209998\n",
      "\n",
      "max_depth = 13\n",
      "F1 score based on validation set: 0.5253456221198156\n",
      "AUC-ROC Score : 0.7353661327231122\n",
      "\n",
      "max_depth = 14\n",
      "F1 score based on validation set: 0.5203252032520325\n",
      "AUC-ROC Score : 0.7226174969195563\n",
      "\n",
      "max_depth = 15\n",
      "F1 score based on validation set: 0.5249406175771971\n",
      "AUC-ROC Score : 0.7148063721175849\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DecisionTreeClassifier\n",
    "for i in range(6, 16):\n",
    "    # Train the models of different max_depth values with training set\n",
    "    model = DecisionTreeClassifier(random_state = 12345, max_depth = i)\n",
    "    model.fit(features_train_1, target_train_1)\n",
    "    # check the models of different max_depth values with the validation set\n",
    "    predict_valid = model.predict(features_valid)\n",
    "    f1 = f1_score(target_valid, predict_valid)\n",
    "    probabilities_valid = model.predict_proba(features_valid)\n",
    "    probabilities_one_valid = probabilities_valid[:, 1]\n",
    "    auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "    print('max_depth =', i)\n",
    "    print('F1 score based on validation set:', f1)\n",
    "    print('AUC-ROC Score :', auc_roc)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier\n",
      "F1 score based on test set: 0.5947521865889213\n",
      "AUC-ROC Score : 0.8197797912059166\n"
     ]
    }
   ],
   "source": [
    "# Choose max_depth = 6 as the final model to be tested\n",
    "model_DecisionTree =  DecisionTreeClassifier(random_state = 12345, max_depth = 6)\n",
    "model_DecisionTree.fit(features_train_1, target_train_1)\n",
    "# Test its recall and precision metrix with testing set\n",
    "predict_test = model_DecisionTree.predict(features_test)\n",
    "print('DecisionTreeClassifier')\n",
    "f1 = f1_score(target_test, predict_test)\n",
    "probabilities_test = model_DecisionTree.predict_proba(features_test)\n",
    "probabilities_one_test = probabilities_test[:, 1]\n",
    "auc_roc = roc_auc_score(target_test, probabilities_one_test)\n",
    "print('F1 score based on test set:', f1)\n",
    "print('AUC-ROC Score :', auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 10\n",
      "F1 score based on validation set: 0.5451807228915663\n",
      "AUC-ROC Score : 0.8214020418940329\n",
      "\n",
      "n_estimators = 20\n",
      "F1 score based on validation set: 0.574344023323615\n",
      "AUC-ROC Score : 0.8381314909346947\n",
      "\n",
      "n_estimators = 30\n",
      "F1 score based on validation set: 0.576923076923077\n",
      "AUC-ROC Score : 0.8418016194331983\n",
      "\n",
      "n_estimators = 40\n",
      "F1 score based on validation set: 0.5891016200294551\n",
      "AUC-ROC Score : 0.8489896145044886\n",
      "\n",
      "n_estimators = 50\n",
      "F1 score based on validation set: 0.5854383358098068\n",
      "AUC-ROC Score : 0.8500994543214222\n",
      "\n",
      "n_estimators = 60\n",
      "F1 score based on validation set: 0.5929203539823009\n",
      "AUC-ROC Score : 0.8494455201549024\n",
      "\n",
      "n_estimators = 70\n",
      "F1 score based on validation set: 0.5857988165680473\n",
      "AUC-ROC Score : 0.8488408730857243\n",
      "\n",
      "n_estimators = 80\n",
      "F1 score based on validation set: 0.5901639344262295\n",
      "AUC-ROC Score : 0.8508387607815524\n",
      "\n",
      "n_estimators = 90\n",
      "F1 score based on validation set: 0.5940298507462686\n",
      "AUC-ROC Score : 0.8500748107727514\n",
      "\n",
      "n_estimators = 100\n",
      "F1 score based on validation set: 0.59882005899705\n",
      "AUC-ROC Score : 0.8520999823974653\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RandomForestClassifier\n",
    "for i in range(1, 11):\n",
    "    # Train the models of different n_estimators values with training set\n",
    "    model = RandomForestClassifier(random_state = 12345, n_estimators = i * 10)\n",
    "    model.fit(features_train_1, target_train_1)\n",
    "    # check the models of different n_estimators values with the validation set\n",
    "    predict_valid = model.predict(features_valid)\n",
    "    f1 = f1_score(target_valid, predict_valid)\n",
    "    probabilities_valid = model.predict_proba(features_valid)\n",
    "    probabilities_one_valid = probabilities_valid[:, 1]\n",
    "    auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "    print('n_estimators =', i * 10)\n",
    "    print('F1 score based on validation set:', f1)\n",
    "    print('AUC-ROC Score :', auc_roc)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 100\n",
      "max_depth = 6\n",
      "F1 score based on validation set: 0.6132478632478633\n",
      "AUC-ROC Score : 0.8681288505544797\n",
      "\n",
      "n_estimators = 100\n",
      "max_depth = 7\n",
      "F1 score based on validation set: 0.6152173913043478\n",
      "AUC-ROC Score : 0.8702411547262805\n",
      "\n",
      "n_estimators = 100\n",
      "max_depth = 8\n",
      "F1 score based on validation set: 0.6146993318485524\n",
      "AUC-ROC Score : 0.8693434254532653\n",
      "\n",
      "n_estimators = 100\n",
      "max_depth = 9\n",
      "F1 score based on validation set: 0.6248548199767712\n",
      "AUC-ROC Score : 0.8699982397465235\n",
      "\n",
      "n_estimators = 100\n",
      "max_depth = 10\n",
      "F1 score based on validation set: 0.6198547215496368\n",
      "AUC-ROC Score : 0.8670480549199086\n",
      "\n",
      "n_estimators = 100\n",
      "max_depth = 11\n",
      "F1 score based on validation set: 0.6\n",
      "AUC-ROC Score : 0.865826439007217\n",
      "\n",
      "n_estimators = 100\n",
      "max_depth = 12\n",
      "F1 score based on validation set: 0.5966277561608301\n",
      "AUC-ROC Score : 0.8588487942263685\n",
      "\n",
      "n_estimators = 100\n",
      "max_depth = 13\n",
      "F1 score based on validation set: 0.607190412782956\n",
      "AUC-ROC Score : 0.8575690899489525\n",
      "\n",
      "n_estimators = 100\n",
      "max_depth = 14\n",
      "F1 score based on validation set: 0.6021798365122616\n",
      "AUC-ROC Score : 0.8573939447280408\n",
      "\n",
      "n_estimators = 100\n",
      "max_depth = 15\n",
      "F1 score based on validation set: 0.5926966292134832\n",
      "AUC-ROC Score : 0.8512990670656575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Specify the n_estimators = 100\n",
    "for i in range(6, 16):\n",
    "    # Train the models of different max_depth values with training set\n",
    "    model = RandomForestClassifier(random_state = 12345, n_estimators = 100, max_depth = i)\n",
    "    model.fit(features_train_1, target_train_1)\n",
    "    # check the models of different max_depth values with the validation set\n",
    "    predict_valid = model.predict(features_valid)\n",
    "    f1 = f1_score(target_valid, predict_valid)\n",
    "    probabilities_valid = model.predict_proba(features_valid)\n",
    "    probabilities_one_valid = probabilities_valid[:, 1]\n",
    "    auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "    print('n_estimators = 100')\n",
    "    print('max_depth =', i)\n",
    "    print('F1 score based on validation set:', f1)\n",
    "    print('AUC-ROC Score :', auc_roc)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier\n",
      "F1 score based on test set: 0.6235294117647059\n",
      "AUC-ROC Score : 0.8587895650519608\n"
     ]
    }
   ],
   "source": [
    "# Choose n_estimators = 100, max_depth = 9 as the final model to be tested\n",
    "model_RandomForest =  RandomForestClassifier(random_state = 12345, n_estimators = 100, max_depth = 9)\n",
    "model_RandomForest.fit(features_train_1, target_train_1)\n",
    "# Test its recall and precision metrix with testing set\n",
    "predict_test = model_RandomForest.predict(features_test)\n",
    "print('RandomForestClassifier')\n",
    "f1 = f1_score(target_test, predict_test)\n",
    "probabilities_test = model_RandomForest.predict_proba(features_test)\n",
    "probabilities_one_test = probabilities_test[:, 1]\n",
    "auc_roc = roc_auc_score(target_test, probabilities_one_test)\n",
    "print('F1 score based on test set:', f1)\n",
    "print('AUC-ROC Score :', auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solver = newton-cg\n",
      "F1 score based on validation set: 0.5184484389782402\n",
      "AUC-ROC Score : 0.794254532652702\n",
      "\n",
      "solver = lbfgs\n",
      "F1 score based on validation set: 0.4466338259441708\n",
      "AUC-ROC Score : 0.7315543038197501\n",
      "\n",
      "solver = liblinear\n",
      "F1 score based on validation set: 0.4526404023470243\n",
      "AUC-ROC Score : 0.7452666784016899\n",
      "\n",
      "solver = sag\n",
      "F1 score based on validation set: 0.3653209794837856\n",
      "AUC-ROC Score : 0.5920735785953177\n",
      "\n",
      "solver = saga\n",
      "F1 score based on validation set: 0.36686390532544383\n",
      "AUC-ROC Score : 0.5864970955817638\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LogisticRegression\n",
    "for method in ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']:\n",
    "    # Train the models of different solver values with training set\n",
    "    model = LogisticRegression(random_state = 12345, solver = method)\n",
    "    model.fit(features_train_1, target_train_1)\n",
    "    # check the models of different solver values with the validation set\n",
    "    predict_valid = model.predict(features_valid)\n",
    "    f1 = f1_score(target_valid, predict_valid)\n",
    "    probabilities_valid = model.predict_proba(features_valid)\n",
    "    probabilities_one_valid = probabilities_valid[:, 1]\n",
    "    auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "    print('solver =', method)\n",
    "    print('F1 score based on validation set:', f1)\n",
    "    print('AUC-ROC Score :', auc_roc)\n",
    "    print()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "F1 score based on test set: 0.505670446964643\n",
      "AUC-ROC Score : 0.762141209483722\n"
     ]
    }
   ],
   "source": [
    "# Choose solver = newton-cg as the final model to be tested\n",
    "model_LogisticRegression =  LogisticRegression(random_state = 12345, solver = 'newton-cg')\n",
    "model_LogisticRegression.fit(features_train_1, target_train_1)\n",
    "# Test its recall and precision metrix with testing set\n",
    "predict_test = model_LogisticRegression.predict(features_test)\n",
    "print('LogisticRegression')\n",
    "f1 = f1_score(target_test, predict_test)\n",
    "probabilities_test = model_LogisticRegression.predict_proba(features_test)\n",
    "probabilities_one_test = probabilities_test[:, 1]\n",
    "auc_roc = roc_auc_score(target_test, probabilities_one_test)\n",
    "print('F1 score based on test set:', f1)\n",
    "print('AUC-ROC Score :', auc_roc)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description**\n",
    "\n",
    "1. When trained with **balanced** data using **upsampling** method, among all the models above, the ***RandomForestClassifier*** model with *random_state = 12345*, *n_estimators = 100* and *max_depth = 9* has the highest **F1 Score (0.6235294117647059)** based on test set.\n",
    "\n",
    "2. When trained with the same models using the same arguments (random_state, n_estimators, max_depth, solver ... etc), the models trained with **balanced** data  using **upsampling** method have *higher F1 Score values*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training with balaced data (Downsampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsampling  those who didn't exit\n",
    "def downsample(features, target, fraction):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_downsampled = pd.concat(\n",
    "        [features_zeros.sample(frac=fraction, random_state=12345)]\n",
    "        + [features_ones]\n",
    "    )\n",
    "    target_downsampled = pd.concat(\n",
    "        [target_zeros.sample(frac=fraction, random_state=12345)]\n",
    "        + [target_ones]\n",
    "    )\n",
    "\n",
    "    features_downsampled, target_downsampled = shuffle(\n",
    "        features_downsampled, target_downsampled, random_state=12345\n",
    "    )\n",
    "\n",
    "    return features_downsampled, target_downsampled\n",
    "\n",
    "features_train_2, target_train_2 = downsample(features_train, target_train, fraction = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Exited : 1122\n",
      "Others : 1126\n"
     ]
    }
   ],
   "source": [
    "# Look into the imbalance classes\n",
    "print('Number of Exited :', target_train_2.sum())    \n",
    "print('Others :', target_train_2.count() - target_train_2.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description**\n",
    "\n",
    "Now the 2 classes are more balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 6\n",
      "F1 score based on validation set: 0.569767441860465\n",
      "AUC-ROC Score : 0.8475294842457313\n",
      "\n",
      "max_depth = 7\n",
      "F1 score based on validation set: 0.5656154628687691\n",
      "AUC-ROC Score : 0.8400378454497447\n",
      "\n",
      "max_depth = 8\n",
      "F1 score based on validation set: 0.5450980392156863\n",
      "AUC-ROC Score : 0.8051196972364021\n",
      "\n",
      "max_depth = 9\n",
      "F1 score based on validation set: 0.5195052331113227\n",
      "AUC-ROC Score : 0.7625523675409258\n",
      "\n",
      "max_depth = 10\n",
      "F1 score based on validation set: 0.514078110808356\n",
      "AUC-ROC Score : 0.7632089420876607\n",
      "\n",
      "max_depth = 11\n",
      "F1 score based on validation set: 0.5\n",
      "AUC-ROC Score : 0.7410834360147861\n",
      "\n",
      "max_depth = 12\n",
      "F1 score based on validation set: 0.488646684831971\n",
      "AUC-ROC Score : 0.7243284632987149\n",
      "\n",
      "max_depth = 13\n",
      "F1 score based on validation set: 0.49329758713136734\n",
      "AUC-ROC Score : 0.7200827319133954\n",
      "\n",
      "max_depth = 14\n",
      "F1 score based on validation set: 0.4829443447037702\n",
      "AUC-ROC Score : 0.7029880302763598\n",
      "\n",
      "max_depth = 15\n",
      "F1 score based on validation set: 0.4865334491746307\n",
      "AUC-ROC Score : 0.7114777327935222\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DecisionTreeClassifier\n",
    "for i in range(6, 16):\n",
    "    # Train the models of different max_depth values with training set\n",
    "    model = DecisionTreeClassifier(random_state = 12345, max_depth = i)\n",
    "    model.fit(features_train_2, target_train_2)\n",
    "    # check the models of different max_depth values with the validation set\n",
    "    predict_valid = model.predict(features_valid)\n",
    "    f1 = f1_score(target_valid, predict_valid)\n",
    "    probabilities_valid = model.predict_proba(features_valid)\n",
    "    probabilities_one_valid = probabilities_valid[:, 1]\n",
    "    auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "    print('max_depth =', i)\n",
    "    print('F1 score based on validation set:', f1)\n",
    "    print('AUC-ROC Score :', auc_roc)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier\n",
      "F1 score based on test set: 0.5933908045977012\n",
      "AUC-ROC Score : 0.8315512116239804\n"
     ]
    }
   ],
   "source": [
    "# Choose max_depth = 6 as the final model to be tested\n",
    "model_DecisionTree =  DecisionTreeClassifier(random_state = 12345, max_depth = 6)\n",
    "model_DecisionTree.fit(features_train_2, target_train_2)\n",
    "# Test its recall and precision metrix with testing set\n",
    "predict_test = model_DecisionTree.predict(features_test)\n",
    "print('DecisionTreeClassifier')\n",
    "f1 = f1_score(target_test, predict_test)\n",
    "probabilities_test = model_DecisionTree.predict_proba(features_test)\n",
    "probabilities_one_test = probabilities_test[:, 1]\n",
    "auc_roc = roc_auc_score(target_test, probabilities_one_test)\n",
    "print('F1 score based on test set:', f1)\n",
    "print('AUC-ROC Score :', auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 10\n",
      "F1 score based on validation set: 0.5540679711637487\n",
      "AUC-ROC Score : 0.8156627354339024\n",
      "\n",
      "n_estimators = 20\n",
      "F1 score based on validation set: 0.577639751552795\n",
      "AUC-ROC Score : 0.83558352402746\n",
      "\n",
      "n_estimators = 30\n",
      "F1 score based on validation set: 0.5705521472392638\n",
      "AUC-ROC Score : 0.8411652878014434\n",
      "\n",
      "n_estimators = 40\n",
      "F1 score based on validation set: 0.5851172273190621\n",
      "AUC-ROC Score : 0.8474907586692484\n",
      "\n",
      "n_estimators = 50\n",
      "F1 score based on validation set: 0.585612968591692\n",
      "AUC-ROC Score : 0.8504013377926422\n",
      "\n",
      "n_estimators = 60\n",
      "F1 score based on validation set: 0.5851703406813628\n",
      "AUC-ROC Score : 0.8527688787185355\n",
      "\n",
      "n_estimators = 70\n",
      "F1 score based on validation set: 0.5849246231155779\n",
      "AUC-ROC Score : 0.8545555359971835\n",
      "\n",
      "n_estimators = 80\n",
      "F1 score based on validation set: 0.5881168177240684\n",
      "AUC-ROC Score : 0.8556732969547615\n",
      "\n",
      "n_estimators = 90\n",
      "F1 score based on validation set: 0.5908629441624367\n",
      "AUC-ROC Score : 0.8580223552191516\n",
      "\n",
      "n_estimators = 100\n",
      "F1 score based on validation set: 0.584\n",
      "AUC-ROC Score : 0.8580989262453794\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RandomForestClassifier\n",
    "for i in range(1, 11):\n",
    "    # Train the models of different n_estimators values with training set\n",
    "    model = RandomForestClassifier(random_state = 12345, n_estimators = i * 10)\n",
    "    model.fit(features_train_2, target_train_2)\n",
    "    # check the models of different n_estimators values with the validation set\n",
    "    predict_valid = model.predict(features_valid)\n",
    "    f1 = f1_score(target_valid, predict_valid)\n",
    "    probabilities_valid = model.predict_proba(features_valid)\n",
    "    probabilities_one_valid = probabilities_valid[:, 1]\n",
    "    auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "    print('n_estimators =', i * 10)\n",
    "    print('F1 score based on validation set:', f1)\n",
    "    print('AUC-ROC Score :', auc_roc)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 90\n",
      "max_depth = 6\n",
      "F1 score based on validation set: 0.5995934959349594\n",
      "AUC-ROC Score : 0.8661292026051752\n",
      "\n",
      "n_estimators = 90\n",
      "max_depth = 7\n",
      "F1 score based on validation set: 0.6081632653061225\n",
      "AUC-ROC Score : 0.8683911283224784\n",
      "\n",
      "n_estimators = 90\n",
      "max_depth = 8\n",
      "F1 score based on validation set: 0.610204081632653\n",
      "AUC-ROC Score : 0.8682978348882239\n",
      "\n",
      "n_estimators = 90\n",
      "max_depth = 9\n",
      "F1 score based on validation set: 0.5957446808510638\n",
      "AUC-ROC Score : 0.8649691955641612\n",
      "\n",
      "n_estimators = 90\n",
      "max_depth = 10\n",
      "F1 score based on validation set: 0.6071065989847715\n",
      "AUC-ROC Score : 0.8634430558000351\n",
      "\n",
      "n_estimators = 90\n",
      "max_depth = 11\n",
      "F1 score based on validation set: 0.6010152284263959\n",
      "AUC-ROC Score : 0.8599911987326176\n",
      "\n",
      "n_estimators = 90\n",
      "max_depth = 12\n",
      "F1 score based on validation set: 0.5924453280318092\n",
      "AUC-ROC Score : 0.8629237810244675\n",
      "\n",
      "n_estimators = 90\n",
      "max_depth = 13\n",
      "F1 score based on validation set: 0.5900990099009901\n",
      "AUC-ROC Score : 0.8610147861292027\n",
      "\n",
      "n_estimators = 90\n",
      "max_depth = 14\n",
      "F1 score based on validation set: 0.5829244357212954\n",
      "AUC-ROC Score : 0.860143460658335\n",
      "\n",
      "n_estimators = 90\n",
      "max_depth = 15\n",
      "F1 score based on validation set: 0.592156862745098\n",
      "AUC-ROC Score : 0.8598855835240274\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Specify the n_estimators = 90\n",
    "for i in range(6, 16):\n",
    "    # Train the models of different max_depth values with training set\n",
    "    model = RandomForestClassifier(random_state = 12345, n_estimators = 100, max_depth = i)\n",
    "    model.fit(features_train_2, target_train_2)\n",
    "    # check the models of different max_depth values with the validation set\n",
    "    predict_valid = model.predict(features_valid)\n",
    "    f1 = f1_score(target_valid, predict_valid)\n",
    "    probabilities_valid = model.predict_proba(features_valid)\n",
    "    probabilities_one_valid = probabilities_valid[:, 1]\n",
    "    auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "    print('n_estimators = 90')\n",
    "    print('max_depth =', i)\n",
    "    print('F1 score based on validation set:', f1)\n",
    "    print('AUC-ROC Score :', auc_roc)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier\n",
      "F1 score based on test set: 0.61880088823094\n",
      "AUC-ROC Score : 0.8560148391239211\n"
     ]
    }
   ],
   "source": [
    "# Choose n_estimators = 90, max_depth = 8 as the final model to be tested\n",
    "model_RandomForest =  RandomForestClassifier(random_state = 12345, n_estimators = 90, max_depth = 8)\n",
    "model_RandomForest.fit(features_train_2, target_train_2)\n",
    "# Test its recall and precision metrix with testing set\n",
    "predict_test = model_RandomForest.predict(features_test)\n",
    "print('RandomForestClassifier')\n",
    "f1 = f1_score(target_test, predict_test)\n",
    "probabilities_test = model_RandomForest.predict_proba(features_test)\n",
    "probabilities_one_test = probabilities_test[:, 1]\n",
    "auc_roc = roc_auc_score(target_test, probabilities_one_test)\n",
    "print('F1 score based on test set:', f1)\n",
    "print('AUC-ROC Score :', auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solver = newton-cg\n",
      "F1 score based on validation set: 0.5088868101028999\n",
      "AUC-ROC Score : 0.7922654462242563\n",
      "\n",
      "solver = lbfgs\n",
      "F1 score based on validation set: 0.4448105436573311\n",
      "AUC-ROC Score : 0.7319433198380567\n",
      "\n",
      "solver = liblinear\n",
      "F1 score based on validation set: 0.45643153526970953\n",
      "AUC-ROC Score : 0.7392853370885408\n",
      "\n",
      "solver = sag\n",
      "F1 score based on validation set: 0.3650586701434159\n",
      "AUC-ROC Score : 0.5825101214574899\n",
      "\n",
      "solver = saga\n",
      "F1 score based on validation set: 0.3605486610058785\n",
      "AUC-ROC Score : 0.5790846681922196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LogisticRegression\n",
    "for method in ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']:\n",
    "    # Train the models of different solver values with training set\n",
    "    model = LogisticRegression(random_state = 12345, solver = method)\n",
    "    model.fit(features_train_2, target_train_2)\n",
    "    # check the models of different solver values with the validation set\n",
    "    predict_valid = model.predict(features_valid)\n",
    "    f1 = f1_score(target_valid, predict_valid)\n",
    "    probabilities_valid = model.predict_proba(features_valid)\n",
    "    probabilities_one_valid = probabilities_valid[:, 1]\n",
    "    auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "    print('solver =', method)\n",
    "    print('F1 score based on validation set:', f1)\n",
    "    print('AUC-ROC Score :', auc_roc)\n",
    "    print()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "F1 score based on test set: 0.5082726671078756\n",
      "AUC-ROC Score : 0.7591067988870658\n"
     ]
    }
   ],
   "source": [
    "# Choose solver = newton-cg as the final model to be tested\n",
    "model_LogisticRegression =  LogisticRegression(random_state = 12345, solver = 'newton-cg')\n",
    "model_LogisticRegression.fit(features_train_2, target_train_2)\n",
    "# Test its recall and precision metrix with testing set\n",
    "predict_test = model_LogisticRegression.predict(features_test)\n",
    "print('LogisticRegression')\n",
    "f1 = f1_score(target_test, predict_test)\n",
    "probabilities_test = model_LogisticRegression.predict_proba(features_test)\n",
    "probabilities_one_test = probabilities_test[:, 1]\n",
    "auc_roc = roc_auc_score(target_test, probabilities_one_test)\n",
    "print('F1 score based on test set:', f1)\n",
    "print('AUC-ROC Score :', auc_roc)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description**\n",
    "\n",
    "1. When trained with **balanced** data using **downsampling** method, among all the models above, the ***RandomForestClassifier*** model with *random_state = 12345*, *n_estimators = 90* and *max_depth = 8* has the highest **F1 Score (0.61880088823094)** based on test set.\n",
    "\n",
    "2. When trained with the same models using the same arguments (random_state, n_estimators, max_depth, solver ... etc), the models trained with **balanced** data  using **downsampling** method have *higher F1 Score values*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Final testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier\n",
      "F1 score based on test set: 0.6235294117647059\n",
      "AUC-ROC Score : 0.8587895650519608\n",
      "Accuracy : 0.8208\n"
     ]
    }
   ],
   "source": [
    "# Choose RandomForestClassifier (n_estimators = 20, max_depth = 15) using upsampling method as the final model to be tested\n",
    "model_RandomForest =  RandomForestClassifier(random_state = 12345, n_estimators = 100, max_depth = 9)\n",
    "model_RandomForest.fit(features_train_1, target_train_1)\n",
    "# Test its recall and precision metrix with testing set\n",
    "predict_test = model_RandomForest.predict(features_test)\n",
    "print('RandomForestClassifier')\n",
    "f1 = f1_score(target_test, predict_test)\n",
    "probabilities_test = model_RandomForest.predict_proba(features_test)\n",
    "probabilities_one_test = probabilities_test[:, 1]\n",
    "auc_roc = roc_auc_score(target_test, probabilities_one_test)\n",
    "print('F1 score based on test set:', f1)\n",
    "print('AUC-ROC Score :', auc_roc)\n",
    "# Test its accuracy\n",
    "print('Accuracy :', accuracy_score(predict_test, target_test))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(target_test, probabilities_one_test)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "# set the boundary for the axes from 0 to 1 >\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "# name the axes \"False Positive Rate\" and \"True Positive Rate\" \n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# add the heading \"ROC curve\" \n",
    "plt.title('ROC curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_RandomForest.joblib']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model\n",
    "dump(model_RandomForest, 'model_RandomForest.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description**\n",
    "\n",
    "This model we tested has an **accuracy of (0.8208)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary\n",
    "\n",
    "1. The original data is very imbalanced. When we train it with different models (DecisionTreeClassifier, RandomForestClassifier, LogisticRegression), ***RandomForestClassifier*** with *random_state = 12345*, *n_estimators = 90* and *max_depth = 14* has the best performance -- **F1 Score (0.5680473372781064)**.\n",
    "\n",
    "2. When we adjust the balance of the data and train it with different models (DecisionTreeClassifier, RandomForestClassifier, LogisticRegression), the ***RandomForestClassifier*** model trained with *upsampled data* with *random_state = 12345*, *n_estimators = 100* and *max_depth = 8* has the best performance -- **F1 Score (0.6235294117647059)**.\n",
    "\n",
    "3. When trained with the same models using the same arguments (random_state, n_estimators, max_depth, solver ... etc), the models trained with **balanced** data have *higher F1 Score values*, thus *better performance*."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
